{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3639294c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-28T07:29:42.240268Z",
     "iopub.status.busy": "2023-07-28T07:29:42.239611Z",
     "iopub.status.idle": "2023-07-28T07:29:42.251111Z",
     "shell.execute_reply": "2023-07-28T07:29:42.249357Z"
    },
    "papermill": {
     "duration": 0.017038,
     "end_time": "2023-07-28T07:29:42.253168",
     "exception": false,
     "start_time": "2023-07-28T07:29:42.236130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.23.5\n",
      "Matplotlib 3.7.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "print(\"Numpy:\", np.__version__)\n",
    "print(\"Matplotlib\", plt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e5dce",
   "metadata": {
    "papermill": {
     "duration": 0.00113,
     "end_time": "2023-07-28T07:29:42.256096",
     "exception": false,
     "start_time": "2023-07-28T07:29:42.254966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Previously in NNFromScratchDotProduct.ipynb, we modelled a single layer of neuron and we'd like to do now is model 2 layers of neurons which we could extrapolate (estimate) out to however many layers of neuron we want & we also going to build a NN object (converting NN to an object).\n",
    "* The 1st thing we need to do is to cover the topic of batches. \n",
    "* Why batch? There are 2 reason for batches:\n",
    "* 1. We can calculate input, weights and bias in parallel. The bigger the batch the more parallel operations that we can run. This is also why we train NN on GPUs not CPUs because to take advantage of GPUs parallel processing power.\n",
    "* 2. The other reason we do it in batches is because it helps with generalization. Meaning we can pass a batch of features (ie: inputs) for fitting. To put it in a simple explaination, rather than showing 1 example at a time, we show multiple example at one time to let the computer to \"generalize\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.069551,
   "end_time": "2023-07-28T07:29:43.078352",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-28T07:29:34.008801",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
