{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c6f2ec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-28T08:00:24.998101Z",
     "iopub.status.busy": "2023-07-28T08:00:24.997515Z",
     "iopub.status.idle": "2023-07-28T08:00:25.015409Z",
     "shell.execute_reply": "2023-07-28T08:00:25.013632Z"
    },
    "papermill": {
     "duration": 0.027536,
     "end_time": "2023-07-28T08:00:25.019058",
     "exception": false,
     "start_time": "2023-07-28T08:00:24.991522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.23.5\n",
      "Matplotlib 3.7.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "print(\"Numpy:\", np.__version__)\n",
    "print(\"Matplotlib\", plt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69410b30",
   "metadata": {
    "papermill": {
     "duration": 0.002698,
     "end_time": "2023-07-28T08:00:25.025187",
     "exception": false,
     "start_time": "2023-07-28T08:00:25.022489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Previously in NNFromScratchDotProduct.ipynb, we modelled a single layer of neuron and we'd like to do now is model 2 layers of neurons which we could extrapolate (estimate) out to however many layers of neuron we want & we also going to build a NN object (converting NN to an object).\n",
    "* The 1st thing we need to do is to cover the topic of batches. \n",
    "* Why batch? There are 2 reason for batches:\n",
    "* 1. We can calculate input, weights and bias in parallel. The bigger the batch the more parallel operations that we can run. This is also why we train NN on GPUs not CPUs because to take advantage of GPUs parallel processing power.\n",
    "* 2. The other reason we do it in batches is because it helps with generalization. Meaning we can pass a batch of features (ie: inputs) for fitting. To put it in a simple explaination, rather than showing 1 example at a time, we show multiple example at one time to let the computer to \"generalize\"\n",
    "* The caveat of batches is, it can cause overfitting. Its like making AI to be a \"smartass\". Having some knowledge but at the same time having wrong assumptions.\n",
    "* Different problems will vary with batch size. Ideally a batch size should be 32, 64 or 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19faf123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T08:00:25.034794Z",
     "iopub.status.busy": "2023-07-28T08:00:25.034089Z",
     "iopub.status.idle": "2023-07-28T08:00:25.056615Z",
     "shell.execute_reply": "2023-07-28T08:00:25.054250Z"
    },
    "papermill": {
     "duration": 0.033404,
     "end_time": "2023-07-28T08:00:25.061489",
     "exception": false,
     "start_time": "2023-07-28T08:00:25.028085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.33225 -3.80535]\n",
      " [ 0.2434  -2.2988  -3.1207 ]\n",
      " [-0.99314  1.1603  -1.89101]]\n"
     ]
    }
   ],
   "source": [
    "# converting single sample of inputs to a batch\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "\n",
    "# weights is a matrix of vectors\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5] # is a vector\n",
    "\n",
    "#Adding another layer, to do that we need another set of weights and biases\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "           [-0.5, -0.12, -0.33],\n",
    "           [-0.44, -0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1, 2, -0.5] \n",
    "\n",
    "\n",
    "#Perform matrix transform to variable weight to avoid shape error\n",
    "#Convert variable weights from python list to arrays then transpose\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.211278,
   "end_time": "2023-07-28T08:00:27.482699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-28T08:00:08.271421",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
